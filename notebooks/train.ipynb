{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:16:51.203782Z",
     "start_time": "2020-02-11T01:16:50.689591Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:16:53.333274Z",
     "start_time": "2020-02-11T01:16:51.205661Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections.abc import Iterable\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import gt, lt, add, sub\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import (accuracy_score, dcg_score, roc_auc_score, \n",
    "                             precision_score, recall_score)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from htools import hdir, LoggerMixin, eprint\n",
    "from ml_htools.torch_utils import ModelMixin, variable_lr_optimizer, DEVICE, stats\n",
    "from spellotape.utils import stop_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:16:53.357869Z",
     "start_time": "2020-02-11T01:16:53.334672Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reproducible testing.\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "\n",
    "- Maybe get different logger and make new folder and/or file for each training run?\n",
    "- Finish + test csvlogger (decide whether to comebine with statshandler)\n",
    "- Build + add + test LRScheduler\n",
    "- Test regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:16:53.385525Z",
     "start_time": "2020-02-11T01:16:53.359320Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, n=64, dim=2):\n",
    "        self.x = torch.rand(n, dim).float()\n",
    "        self.y = torch.clamp(\n",
    "            (self.x[:, 0]*.75 + self.x[:, 1]*.25).round(), 0, 1\n",
    "        ).abs().unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:19:04.886844Z",
     "start_time": "2020-02-11T01:19:04.838232Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module, LoggerMixin):\n",
    "    \n",
    "    def __init__(self, dim, criterion, path=os.path.join('..', 'data'),\n",
    "                 callbacks=None, metrics=None):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(dim, 1)\n",
    "        self.criterion = criterion    \n",
    "        # Dictionary makes it easier to adjust callbacks after creating model.\n",
    "        callbacks = [ModelHandler(), StatsHandler(), MetricPrinter()] \\\n",
    "                    + (callbacks or [])\n",
    "        self.callbacks = {type(cb).__name__: cb for cb in callbacks}\n",
    "        self.metrics = [batch_size] + (metrics or [])\n",
    "        self.logger = self.get_logger(os.path.join(path, 'train.log'), \n",
    "                                      fmt='\\n%(asctime)s\\n %(message)s')\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "    \n",
    "    def fit(self, epochs, loaders, lrs, optim=None, callbacks=None, \n",
    "            metrics=None, classify=True, logit=True, thresh=.5,\n",
    "            device=DEVICE):\n",
    "        # Initialize stats, data loaders, optimizer, and callbacks.\n",
    "        stats = defaultdict(list)\n",
    "        train_dl, val_dl = loaders\n",
    "        optim = optim or variable_lr_optimizer(self, lrs=lrs)\n",
    "        _ = self.stop_training('on_train_begin', callbacks, metrics)\n",
    "            \n",
    "        # Train.\n",
    "        for epoch in range(1, epochs+1):\n",
    "            _ = self.stop_training('on_epoch_begin', epoch, stats)\n",
    "            for i, (xb, yb) in enumerate(train_dl, 1):\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                optim.zero_grad()\n",
    "                _ = self.stop_training('on_batch_begin')\n",
    "                \n",
    "                # Forward and backward passes.\n",
    "                y_score = self(xb)\n",
    "                loss = self.criterion(y_score, yb)\n",
    "                loss.backward()\n",
    "                optim.step()\n",
    "                \n",
    "                # Separate because callbacks are only applied during training.\n",
    "                self._update_stats(stats, loss, yb, y_score.detach(),\n",
    "                                   classify, logit, thresh)\n",
    "                if self.stop_training('on_batch_end', stats): break\n",
    "            \n",
    "            # If on_batch_end callback halts training, else block is skipped.  \n",
    "            else: \n",
    "                val_stats = self.validate(val_dl, classify, logit, thresh)\n",
    "                if self.stop_training('on_epoch_end', epoch, stats, val_stats):\n",
    "                    break\n",
    "                continue\n",
    "            break      \n",
    "\n",
    "        self.stop_training('on_train_end', stats, val_stats)\n",
    "            \n",
    "    def validate(self, val_dl, classify, logit, thresh):\n",
    "        val_stats = defaultdict(list)\n",
    "        self.eval()\n",
    "        with torch.no_grad():\n",
    "            for xb, yb in val_dl:\n",
    "                y_score = self(xb)\n",
    "                loss = self.criterion(y_score, yb)\n",
    "                self._update_stats(val_stats, loss, yb, y_score, classify,\n",
    "                                   logit, thresh)\n",
    "        return val_stats\n",
    "    \n",
    "    def _update_stats(self, stats, loss, yb, y_score, classify, logit, thresh):\n",
    "        \"\"\"Update stats in place.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        stats: defaultdict[str, list]\n",
    "        loss: torch.Tensor\n",
    "            Tensor containing single value (mini-batch loss).\n",
    "        yb: torch.Tensor\n",
    "            Mini-batch of labels.\n",
    "        y_pred: torch.Tensor\n",
    "            Mini-batch of predictions.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        if classify:\n",
    "            if logit: y_score = torch.sigmoid(y_score)\n",
    "            y_pred = (y_score > thresh).float()\n",
    "            \n",
    "        stats['loss'].append(loss.detach().cpu().numpy().item())\n",
    "        for m in self.metrics:\n",
    "            yhat = y_pred if hasarg(m, 'y_pred') else y_score\n",
    "            stats[m.__name__.replace('_score', '')].append(m(yb, yhat))\n",
    "    \n",
    "    def stop_training(self, attr, *args, **kwargs):\n",
    "        self._stop_training = False\n",
    "        # Pass model object as first argument to callbacks.\n",
    "        for cb in self.callbacks.values():\n",
    "            getattr(cb, attr)(self, *args, **kwargs)\n",
    "        return self._stop_training\n",
    "    \n",
    "    def dims(self):\n",
    "        \"\"\"Get shape of each layer's weights.\"\"\"\n",
    "        return [tuple(p.shape) for p in self.parameters()]\n",
    "\n",
    "    def trainable(self):\n",
    "        \"\"\"Check which layers are trainable.\"\"\"\n",
    "        return [(tuple(p.shape), p.requires_grad) for p in self.parameters()]\n",
    "\n",
    "    def weight_stats(self):\n",
    "        \"\"\"Check mean and standard deviation of each layer's weights.\"\"\"\n",
    "        return [stats(p.data, 3) for p in self.parameters()]\n",
    "\n",
    "    def plot_weights(self):\n",
    "        \"\"\"Plot histograms of each layer's weights.\"\"\"\n",
    "        n_layers = len(self.dims())\n",
    "        fig, ax = plt.subplots(n_layers, figsize=(8, n_layers * 1.25))\n",
    "        if not isinstance(ax, Iterable): ax = [ax]\n",
    "        for i, p in enumerate(self.parameters()):\n",
    "            ax[i].hist(p.data.flatten())\n",
    "            ax[i].set_title(f'Shape: {tuple(p.shape)} Stats: {stats(p.data)}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:18:09.299192Z",
     "start_time": "2020-02-11T01:18:09.273839Z"
    }
   },
   "outputs": [],
   "source": [
    "class TorchCallback:\n",
    "    \n",
    "    def on_train_begin(self, model, callbacks, metrics):\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self, model, stats, val_stats):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_begin(self, model, epoch, stats):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        pass\n",
    "    \n",
    "    def on_batch_begin(self, model):\n",
    "        pass\n",
    "    \n",
    "    def on_batch_end(self, model, stats):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:18:09.587846Z",
     "start_time": "2020-02-11T01:18:09.557047Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopper(TorchCallback):\n",
    "    \n",
    "    def __init__(self, goal, stat='loss', min_improvement=0.0, patience=3):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        goal: str\n",
    "            Indicates what we want to do to the metric in question.\n",
    "            Either 'min' or 'max'. E.g. metric 'loss' should have goal 'min'\n",
    "            while metric 'precision' should have goal 'max'.\n",
    "        stat: str\n",
    "            Quantity to monitor. This will always be computed on the \n",
    "            validation set.\n",
    "        min_improvement: float\n",
    "            Amount of change needed to qualify as improvement. For example,\n",
    "            min_improvement of 0.0 means any improvement is sufficient. With\n",
    "            a min_improvent of 0.2, we will stop training even if the\n",
    "            quantity improves by, for example, 0.1.\n",
    "        patience: int\n",
    "            Number of acceptable epochs without improvement. E.g. patience=0 \n",
    "            means the metric must improve every epoch for training to continue.            \n",
    "        \"\"\"\n",
    "        # Will use op like: self.op(new_val, current_best)\n",
    "        if goal == 'min':\n",
    "            self.init_stat = self.best_stat = float('inf')\n",
    "            self.op = lt\n",
    "            self.op_best = sub\n",
    "        elif goal == 'max':\n",
    "            self.init_stat = self.best_stat = float('-inf')\n",
    "            self.op = gt\n",
    "            self.op_best = add\n",
    "        else:\n",
    "            raise ValueError('Goal must be \"min\" or \"max\".')\n",
    "            \n",
    "        self.stat = stat\n",
    "        self.min_improvement = min_improvement\n",
    "        self.patience = patience\n",
    "        self.since_improvement = 0\n",
    "        \n",
    "    def on_train_begin(self, model, callbacks, metrics):\n",
    "        \"\"\"Resets tracked variables at start of training.\"\"\"\n",
    "        self.best_stat = self.init_stat\n",
    "        self.since_improvement = 0\n",
    "    \n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        new_val = val_stats.get(self.stat, None)\n",
    "        if new_val is None:\n",
    "            model.logger.info(f'EarlyStopper could not find {self.stat}.'\n",
    "                              f'Callback behavior may not be enforced.')\n",
    "            \n",
    "        if self.op(new_val, self.op_best(self.best_stat, self.min_improvement)):\n",
    "            self.best_stat = new_val\n",
    "            self.since_improvement = 0\n",
    "        else:\n",
    "            self.since_improvement += 1\n",
    "            if self.since_improvement > self.patience:\n",
    "                model.logger.info(\n",
    "                    f'EarlyStopper halting training: validation {self.stat} '\n",
    "                    f'has not improved enough in {self.since_improvement} epochs.'\n",
    "                )\n",
    "                model._stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:18:09.781725Z",
     "start_time": "2020-02-11T01:18:09.753859Z"
    }
   },
   "outputs": [],
   "source": [
    "class PerformanceThreshold(TorchCallback):\n",
    "    \n",
    "    def __init__(self, metric, goal, threshold, split='val'):\n",
    "        assert split in ('train', 'val'), 'Split must be \"train\" or \"val\".'\n",
    "        assert goal in ('min', 'max'), 'Goal must be \"min\" or \"max\"'\n",
    "        \n",
    "        self.metric = metric\n",
    "        self.threshold = threshold\n",
    "        self.split = split\n",
    "        self.op = gt if goal == 'min' else lt\n",
    "        \n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        data = val_stats if self.split == 'val' else stats\n",
    "        new_val = data.get(self.metric, None)\n",
    "        if new_val is None:\n",
    "            model.logger.info(f'{self.metric} not found in metrics.'\n",
    "                              'PerformanceThreshold may not be enforced.')\n",
    "            return\n",
    "        \n",
    "        if self.op(new_val, self.threshold):\n",
    "            model.logger.info(\n",
    "                f'PerformanceThreshold halting training: {self.metric} '\n",
    "                f'of {new_val:.4f} did not meet threshold.'\n",
    "            )\n",
    "            model._stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:18:09.934978Z",
     "start_time": "2020-02-11T01:18:09.909809Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricPrinter(TorchCallback):\n",
    "    \n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        data = [[k, v, val_stats[k]] for k, v in stats.items()]\n",
    "        table = tabulate(data, headers=['Metric', 'Train', 'Validation'], \n",
    "                         tablefmt='github', floatfmt='.4f')\n",
    "        model.logger.info(f'Epoch {epoch}\\n\\n{table}\\n\\n{\"=\"*9}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:21:07.591752Z",
     "start_time": "2020-02-11T01:21:07.565323Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelHandler(TorchCallback):\n",
    "    \"\"\"Handles basic model tasks like putting the model on the GPU\n",
    "    and switching between train and eval modes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def on_train_begin(self, model, callbacks, metrics):\n",
    "        model.to(DEVICE)\n",
    "        if callbacks: model.callbacks.update(\n",
    "            {type(cb).__name__: cb for cb in callbacks}\n",
    "        )\n",
    "        if metrics: model.metrics.extend(metrics)\n",
    "        \n",
    "    def on_epoch_begin(self, model, epoch, stats):\n",
    "        model.train()\n",
    "        \n",
    "    def on_train_end(self, model, stats, val_stats):\n",
    "        model.logger.info('Training complete. Model in eval mode.')\n",
    "        model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:17.302214Z",
     "start_time": "2020-02-11T01:20:17.276820Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatsHandler(TorchCallback):\n",
    "        \n",
    "    def on_epoch_begin(self, model, epoch, stats):\n",
    "        stats.clear()\n",
    "        \n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        for group in (stats, val_stats):\n",
    "            for k, v in group.items():\n",
    "                if k == 'batch_size': continue\n",
    "                group[k] = np.average(v, weights=group['batch_size'])\n",
    "            group.pop('batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:17.446449Z",
     "start_time": "2020-02-11T01:20:17.420173Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVLogger(TorchCallback):\n",
    "    \"\"\"Separate from StatsHandler in case we don't want to log outputs.\"\"\"\n",
    "    \n",
    "    def __init__(self, mode='epoch', file_fmt='{}_stats.csv'):\n",
    "        assert mode in ('epoch', 'batch'), \\\n",
    "            'Mode must be \"epoch\" or \"batch\".'\n",
    "        self.mode = mode\n",
    "        self.history = defaultdict(list)\n",
    "        self.fname = file_fmt.format(mode)\n",
    "        \n",
    "    def on_train_begin(self, model, callbacks, metrics):\n",
    "        pass\n",
    "        \n",
    "    def on_batch_end(self, model, stats):\n",
    "        if self.mode != 'batch':\n",
    "            pass\n",
    "        pass\n",
    "        \n",
    "    def on_epoch_end(self, model, epoch, stats, val_stats):\n",
    "        if self.mode != 'epoch':\n",
    "            pass\n",
    "        \n",
    "    def write_csv(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:17.580308Z",
     "start_time": "2020-02-11T01:20:17.555568Z"
    }
   },
   "outputs": [],
   "source": [
    "class EC2Closer(TorchCallback):\n",
    "    \n",
    "    def on_train_end(self, model, stats, val_stats):\n",
    "        stop_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:17.879681Z",
     "start_time": "2020-02-11T01:20:17.854280Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PerformanceThreshold'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(PerformanceThreshold('loss', 'min', 0.5)).__name__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Keep sklearn pattern with y_true as first argument.\n",
    "\n",
    "For classification problems, round probabilities once instead of in every metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.166086Z",
     "start_time": "2020-02-11T01:20:18.142042Z"
    }
   },
   "outputs": [],
   "source": [
    "def hasarg(func, arg):\n",
    "    return arg in inspect.signature(func).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.305836Z",
     "start_time": "2020-02-11T01:20:18.282221Z"
    }
   },
   "outputs": [],
   "source": [
    "def percent_positive(y_true, y_pred):\n",
    "    return (y_pred == 1).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.454139Z",
     "start_time": "2020-02-11T01:20:18.430149Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_soft_prediction(y_true, y_score):\n",
    "    return y_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.610830Z",
     "start_time": "2020-02-11T01:20:18.587159Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_size(y_true, y_pred):\n",
    "    return y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.772428Z",
     "start_time": "2020-02-11T01:20:18.747090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hasarg(roc_auc_score, val) for val in ('y_score', 'y_pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:18.929114Z",
     "start_time": "2020-02-11T01:20:18.903604Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hasarg(precision_score, val) for val in ('y_score', 'y_pred')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:19.221999Z",
     "start_time": "2020-02-11T01:20:19.197555Z"
    }
   },
   "outputs": [],
   "source": [
    "DIM = 2\n",
    "metrics = [accuracy_score, \n",
    "           precision_score, \n",
    "           recall_score, \n",
    "           percent_positive,\n",
    "           mean_soft_prediction\n",
    "          ]\n",
    "callbacks = [EarlyStopper('max', 'accuracy', patience=3),\n",
    "             PerformanceThreshold('recall', 'max', 0.25)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:19.371716Z",
     "start_time": "2020-02-11T01:20:19.346870Z"
    }
   },
   "outputs": [],
   "source": [
    "train = Data(n=34, dim=DIM)\n",
    "val = Data(n=30, dim=DIM)\n",
    "\n",
    "dl_train = DataLoader(train, batch_size=8, shuffle=True)\n",
    "dl_val = DataLoader(val, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:19.528063Z",
     "start_time": "2020-02-11T01:20:19.502183Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = Model(DIM, F.binary_cross_entropy_with_logits, callbacks=callbacks,\n",
    "            metrics=metrics)\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-11T01:20:19.937445Z",
     "start_time": "2020-02-11T01:20:19.655133Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "\n",
      "2020-02-10 17:20:19,707\n",
      " Epoch 1\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.6467 |       0.5533 |\n",
      "| accuracy             |  0.6471 |       0.8333 |\n",
      "| precision            |  0.4235 |       0.8333 |\n",
      "| recall               |  0.7059 |       0.8000 |\n",
      "| percent_positive     |  0.5000 |       0.3667 |\n",
      "| mean_soft_prediction |  0.5016 |       0.4430 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,735\n",
      " Epoch 2\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.5265 |       0.4700 |\n",
      "| accuracy             |  0.8235 |       0.9000 |\n",
      "| precision            |  0.7686 |       0.8111 |\n",
      "| recall               |  0.7569 |       1.0000 |\n",
      "| percent_positive     |  0.4412 |       0.5000 |\n",
      "| mean_soft_prediction |  0.4921 |       0.5264 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,763\n",
      " Epoch 3\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.4473 |       0.3995 |\n",
      "| accuracy             |  0.9412 |       0.9333 |\n",
      "| precision            |  0.8627 |       1.0000 |\n",
      "| recall               |  0.8941 |       0.8667 |\n",
      "| percent_positive     |  0.4412 |       0.3333 |\n",
      "| mean_soft_prediction |  0.4995 |       0.4224 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,792\n",
      " Epoch 4\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.4011 |       0.3552 |\n",
      "| accuracy             |  0.9118 |       0.9333 |\n",
      "| precision            |  1.0000 |       1.0000 |\n",
      "| recall               |  0.8588 |       0.8667 |\n",
      "| percent_positive     |  0.3529 |       0.3333 |\n",
      "| mean_soft_prediction |  0.4144 |       0.4011 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,820\n",
      " Epoch 5\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.3512 |       0.3109 |\n",
      "| accuracy             |  0.9412 |       0.9667 |\n",
      "| precision            |  0.9412 |       1.0000 |\n",
      "| recall               |  0.8157 |       0.9333 |\n",
      "| percent_positive     |  0.3824 |       0.3667 |\n",
      "| mean_soft_prediction |  0.4426 |       0.4579 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,847\n",
      " Epoch 6\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.3101 |       0.2818 |\n",
      "| accuracy             |  0.9118 |       0.9667 |\n",
      "| precision            |  0.9020 |       1.0000 |\n",
      "| recall               |  0.9529 |       0.9333 |\n",
      "| percent_positive     |  0.4706 |       0.3667 |\n",
      "| mean_soft_prediction |  0.4796 |       0.4526 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,876\n",
      " Epoch 7\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.2854 |       0.2572 |\n",
      "| accuracy             |  0.9412 |       0.9667 |\n",
      "| precision            |  0.9216 |       1.0000 |\n",
      "| recall               |  0.9529 |       0.9333 |\n",
      "| percent_positive     |  0.4412 |       0.3667 |\n",
      "| mean_soft_prediction |  0.4742 |       0.4448 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,904\n",
      " Epoch 8\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.2622 |       0.2379 |\n",
      "| accuracy             |  0.9412 |       0.9667 |\n",
      "| precision            |  0.8824 |       1.0000 |\n",
      "| recall               |  0.8941 |       0.9333 |\n",
      "| percent_positive     |  0.4412 |       0.3667 |\n",
      "| mean_soft_prediction |  0.4679 |       0.4228 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,933\n",
      " Epoch 9\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.2459 |       0.2248 |\n",
      "| accuracy             |  0.9706 |       0.9667 |\n",
      "| precision            |  0.9412 |       1.0000 |\n",
      "| recall               |  0.8824 |       0.9333 |\n",
      "| percent_positive     |  0.4118 |       0.3667 |\n",
      "| mean_soft_prediction |  0.4396 |       0.3982 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-10 17:20:19,934\n",
      " EarlyStopper halting training: validation accuracy has not improved enough in 4 epochs.\n",
      "\n",
      "2020-02-10 17:20:19,935\n",
      " Training complete. Model in eval mode.\n"
     ]
    }
   ],
   "source": [
    "net.fit(10, [dl_train, dl_val], [.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T21:42:49.119439Z",
     "start_time": "2020-02-12T21:42:49.059744Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 827,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:37:56.232841Z",
     "start_time": "2020-02-12T23:37:56.199277Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from collections.abc import Iterable\n",
    "import gc\n",
    "import inspect\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from operator import gt, lt, add, sub\n",
    "import os\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import (accuracy_score, dcg_score, roc_auc_score, \n",
    "                             precision_score, recall_score)\n",
    "from textblob import TextBlob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "import warnings\n",
    "\n",
    "from accio.s3tool import S3tool\n",
    "from htools import hdir, LoggerMixin, eprint, assert_raises, auto_repr\n",
    "from ml_htools.torch_utils import (ModelMixin, variable_lr_optimizer,\n",
    "                                   update_optimizer, DEVICE, stats, adam)\n",
    "from spellotape.utils import stop_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T21:42:49.385935Z",
     "start_time": "2020-02-12T21:42:49.353884Z"
    }
   },
   "outputs": [],
   "source": [
    "# Reproducible testing.\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do:\n",
    "\n",
    "- Maybe get different logger and make new folder and/or file for each training run?\n",
    "- Finish + test csvlogger (decide whether to comebine with statshandler)\n",
    "- Build + add + test LRScheduler\n",
    "- Test regression\n",
    "- s3 upload callback\n",
    "- Handle case when softmax needed on outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T00:10:42.826164Z",
     "start_time": "2020-02-12T00:10:42.800581Z"
    }
   },
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \n",
    "    def __init__(self, n=64, dim=2):\n",
    "        self.x = torch.rand(n, dim).float()\n",
    "        self.y = torch.clamp(\n",
    "            (self.x[:, 0]*.75 + self.x[:, 1]*.25).round(), 0, 1\n",
    "        ).abs().unsqueeze(-1)\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        return self.x[i], self.y[i]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:13:15.569124Z",
     "start_time": "2020-02-13T00:13:15.512145Z"
    }
   },
   "outputs": [],
   "source": [
    "class Trainer(LoggerMixin):\n",
    "    \n",
    "    def __init__(self, net, ds_train, ds_val, dl_train, dl_val,\n",
    "                 criterion, out_dir, bucket=None, optim=Adam, eps=1e-3, \n",
    "                 last_act=None, threshold=0.5,\n",
    "                 metrics=None, callbacks=None, device=DEVICE):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        last_act: callable or None\n",
    "            Last activation function to be applied outside the model. \n",
    "            For example, for a binary classification problem, if we choose\n",
    "            to use binary_cross_entropy_with_logits loss but want to compute\n",
    "            some metric using soft predictions, we would pass in torch.sigmoid\n",
    "            for last act. For a multi-class problem using F.cross_entropy loss,\n",
    "            we would need to pass in F.softmax to compute predicted \n",
    "            probabilities.  Remember this is ONLY necessary if all of the \n",
    "            following conditions are met:\n",
    "            1. It is a classification problem.\n",
    "            2. We have excluded the final activation from our model for \n",
    "            numerical stability reasons. (I.E. the loss function has the \n",
    "            the final activation built into it.)\n",
    "            3. We wish to compute 1 or more metrics based on soft predictions,\n",
    "            such as AUC-ROC.\n",
    "        optim: torch.optim callable\n",
    "            Callable optimizer. The default is Adam.\n",
    "        threshold: float or None\n",
    "            For a classification problem, pass in the decision threshold to\n",
    "            use when converting soft predictions to hard predictions. For a\n",
    "            regression problem, pass in None.\n",
    "        \"\"\"\n",
    "        self.net = net\n",
    "        self.ds_train, self.ds_val = ds_train, ds_val\n",
    "        self.dl_train, self.dl_val = dl_train, dl_val\n",
    "        \n",
    "        # LR(s) will be updated in fit() method.\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')\n",
    "            self.optim = variable_lr_optimizer(net, optimizer=optim, eps=eps)\n",
    "        self.criterion = criterion\n",
    "        self.device = DEVICE\n",
    "        self.last_act = last_act\n",
    "        self.thresh = threshold\n",
    "        self._stop_training = False\n",
    "        self.logger = None\n",
    "    \n",
    "        # Storage options.\n",
    "        self.out_dir = out_dir\n",
    "        self.bucket = bucket\n",
    "        os.makedirs(out_dir, exist_ok=True)\n",
    "        \n",
    "        # Dict makes it easier to adjust callbacks after creating model.\n",
    "        self.callbacks = {}\n",
    "        self.add_callbacks(*[BasicConfig(), StatsHandler(), MetricPrinter()] \n",
    "                           + (callbacks or []))\n",
    "        self.metrics = [batch_size] + (metrics or [])\n",
    "    \n",
    "    def save(self, fname):\n",
    "        save(self, os.path.join(self.out_dir, fname))\n",
    "        \n",
    "    def load(self, fname):\n",
    "        \"\"\"This lets a trainer load a previously saved state. This is NOT\n",
    "        an in-place operation: the new trainer is simply returned.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        fname: str\n",
    "            Name of file where Trainer object is stored. Must end in either\n",
    "            .zip or .pkl. Do not include the full path. This automatically\n",
    "            checks the output directory.\n",
    "        \n",
    "        Examples\n",
    "        --------\n",
    "        trainer = Trainer(...)\n",
    "        trainer.fit(...)\n",
    "        trainer.save('v1')\n",
    "        trainer = trainer.load('v1')\n",
    "        \"\"\"\n",
    "        return load(self, os.path.join(self.out_dir, fname))\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_file(path):\n",
    "        \"\"\"Ths lets us load a previously saved Trainer. Unlike load(), this\n",
    "        does not require us to have a Trainer instance first. The intent is\n",
    "        that load() works well when within a single Jupyter notebook session,\n",
    "        but when returning to work on a different day, we may not have a live\n",
    "        instance of Trainer and a staticmethod lets us load without\n",
    "        remembering all the arguments used at initialization time.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        path: str\n",
    "            Full path to saved file. This differs from load() because here, we\n",
    "            don't have an instance with an out_dir attribute to check.\n",
    "        \"\"\"\n",
    "        return load(path)\n",
    "    \n",
    "    def add_callbacks(self, *callbacks):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        callbacks: TorchCallback\n",
    "            One or more callbacks to append to \n",
    "        \"\"\"\n",
    "        self.callbacks.update({type(cb).__name__: cb for cb in callbacks})\n",
    "        self.callbacks = dict(sorted(self.callbacks.items(),\n",
    "                                     key=lambda x: x[1].priority))\n",
    "    \n",
    "    def add_metrics(self, *metrics):\n",
    "        self.metrics.extend(metrics)\n",
    "    \n",
    "    def fit(self, epochs, lrs=3e-3): \n",
    "        stats = defaultdict(list)\n",
    "        sum_i = 0\n",
    "        _ = self.decide_stop_training('on_train_begin', lrs)\n",
    "        for e in range(1, epochs+1):\n",
    "            _ = self.decide_stop_training('on_epoch_begin', e, stats, None)\n",
    "            for i, batch in enumerate(self.dl_train, 1):\n",
    "                sum_i += 1\n",
    "                *xb, yb = map(lambda x: x.to(self.device), batch)\n",
    "                self.optim.zero_grad()\n",
    "                _ = self.decide_stop_training('on_batch_begin', i, sum_i, stats)\n",
    "                \n",
    "                # Forward and backward passes.\n",
    "                y_score = self.net(*xb)\n",
    "                loss = self.criterion(y_score, yb)\n",
    "                loss.backward()\n",
    "                self.optim.step()\n",
    "                \n",
    "                # Separate because callbacks are only applied during training.\n",
    "                self._update_stats(stats, loss, yb, y_score.detach())\n",
    "                if self.decide_stop_training('on_batch_end', i, sum_i, stats): \n",
    "                    break\n",
    "            \n",
    "            # If on_batch_end callback halts training, else block is skipped.  \n",
    "            else: \n",
    "                val_stats = self.validate()\n",
    "                if self.decide_stop_training('on_epoch_end', e, stats, val_stats):\n",
    "                    break\n",
    "                continue\n",
    "            break      \n",
    "\n",
    "        _ = self.decide_stop_training('on_train_end', e, stats, val_stats)\n",
    "    \n",
    "    def validate(self, dl_val=None):\n",
    "        # Allow user to pass in different loader outside of training.\n",
    "        dl_val = self.dl_val or dl_val\n",
    "        val_stats = defaultdict(list)\n",
    "        self.net.eval()\n",
    "        with torch.no_grad():\n",
    "            for batch in dl_val:\n",
    "                *xb, yb = map(lambda x: x.to(self.device), batch)\n",
    "                y_score = self.net(*xb)\n",
    "                loss = self.criterion(y_score, yb)\n",
    "                self._update_stats(val_stats, loss, yb, y_score)\n",
    "        return val_stats\n",
    "        \n",
    "    def _update_stats(self, stats, loss, yb, y_score):\n",
    "        \"\"\"Update stats in place.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        stats: defaultdict[str, list]\n",
    "        loss: torch.Tensor\n",
    "            Tensor containing single value (mini-batch loss).\n",
    "        yb: torch.Tensor\n",
    "            Mini-batch of labels.\n",
    "        y_pred: torch.Tensor\n",
    "            Mini-batch of predictions.\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            y_score = self.last_act(y_score)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        y_pred = (y_score > self.thresh).float() if self.thresh else y_score\n",
    "            \n",
    "        stats['loss'].append(loss.detach().cpu().numpy().item())\n",
    "        for m in self.metrics:\n",
    "            yhat = y_pred if hasarg(m, 'y_pred') else y_score\n",
    "            stats[m.__name__.replace('_score', '')].append(m(yb, yhat))\n",
    "        \n",
    "    def decide_stop_training(self, attr, *args, **kwargs):\n",
    "        self._stop_training = False\n",
    "        # Pass model object as first argument to callbacks.\n",
    "        for cb in self.callbacks.values():\n",
    "            getattr(cb, attr)(self, *args, **kwargs)\n",
    "        return self._stop_training\n",
    "    \n",
    "    def unfreeze(self, n_layers=None, n_groups=None):\n",
    "        \"\"\"Pass in either the number of layers or number of groups to \n",
    "        unfreeze. Unfreezing always starts at the end of the network and moves\n",
    "        backward (e.g. n_layers=1 will unfreeze the last 1 layer, or n_groups=2 \n",
    "        will unfreeze the last 2 groups.) Remember than weights and biases are \n",
    "        treated as separate layers.\n",
    "        \"\"\"\n",
    "        self.net.unfreeze(n_layers, n_groups)\n",
    "            \n",
    "    def freeze(self):\n",
    "        \"\"\"Freeze whole network.\"\"\"\n",
    "        self.net.unfreeze(n_layers=0)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        r = (f'Trainer(criterion={repr(self.criterion.__name__)}, '\n",
    "             f'out_dir={repr(self.out_dir)}, bucket={repr(self.bucket)})'\n",
    "             f'\\n\\nDatasets: {len(self.ds_train)} train rows, '\n",
    "             f'{len(self.ds_val)} val rows'\n",
    "             f'\\n\\nOptimizer: {repr(self.optim)}'\n",
    "             f'\\n\\n{repr(self.net)})')\n",
    "        return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:53.670373Z",
     "start_time": "2020-02-12T23:04:53.630174Z"
    }
   },
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    \n",
    "    def unfreeze(self, n_layers=None, n_groups=None):\n",
    "        \"\"\"Pass in either the number of layers or number of groups to \n",
    "        unfreeze. Unfreezing always starts at the end of the network and moves\n",
    "        backward (e.g. n_layers=1 will unfreeze the last 1 layer, or n_groups=2 \n",
    "        will unfreeze the last 2 groups.) Remember than weights and biases are \n",
    "        treated as separate layers.\n",
    "        \"\"\"\n",
    "        if n_groups is not None: \n",
    "            self._unfreeze_by_group(n_groups)\n",
    "            return\n",
    "\n",
    "        length = len(self)\n",
    "        for i, p in enumerate(self.parameters()):\n",
    "            p.requires_grad = i >= length - n_layers\n",
    "            \n",
    "    def freeze(self):\n",
    "        \"\"\"Freeze whole network.\"\"\"\n",
    "        self.unfreeze(n_layers=0)\n",
    "        \n",
    "    def _unfreeze_by_group(self, n_groups):\n",
    "        \"\"\"Helper for unfreeze() method.\"\"\"\n",
    "        length = len(self.groups)\n",
    "        for i, group in enumerate(self.groups):\n",
    "            setting = i >= length - n_groups\n",
    "            for p in group.parameters():\n",
    "                p.requires_grad = setting\n",
    "                \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of parameter matrices in model (basically number of layers, \n",
    "        except that biases are counted separately).\n",
    "        \"\"\"\n",
    "        return sum(1 for p in self.parameters())\n",
    "    \n",
    "    def dims(self):\n",
    "        \"\"\"Get shape of each layer's weights.\"\"\"\n",
    "        return [tuple(p.shape) for p in self.parameters()]\n",
    "\n",
    "    def trainable(self):\n",
    "        \"\"\"Check which layers are trainable.\"\"\"\n",
    "        return [(tuple(p.shape), p.requires_grad) for p in self.parameters()]\n",
    "\n",
    "    def weight_stats(self):\n",
    "        \"\"\"Check mean and standard deviation of each layer's weights.\"\"\"\n",
    "        return [stats(p.data, 3) for p in self.parameters()]\n",
    "\n",
    "    def plot_weights(self):\n",
    "        \"\"\"Plot histograms of each layer's weights.\"\"\"\n",
    "        n_layers = len(self.dims())\n",
    "        fig, ax = plt.subplots(n_layers, figsize=(8, n_layers * 1.25))\n",
    "        if not isinstance(ax, Iterable): ax = [ax]\n",
    "        for i, p in enumerate(self.parameters()):\n",
    "            ax[i].hist(p.data.flatten())\n",
    "            ax[i].set_title(f'Shape: {tuple(p.shape)} Stats: {stats(p.data)}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:53.819059Z",
     "start_time": "2020-02-12T23:04:53.789356Z"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleModel(BaseModel):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()  \n",
    "        self.fc1 = nn.Linear(dim, 2)\n",
    "        self.fc2 = nn.Linear(2, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.035268Z",
     "start_time": "2020-02-12T23:04:54.003813Z"
    }
   },
   "outputs": [],
   "source": [
    "class GroupedModel(BaseModel):\n",
    "    \n",
    "    def __init__(self, dim):\n",
    "        super().__init__()  \n",
    "        g1 = nn.Sequential(\n",
    "            nn.Linear(dim, 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        g2 = nn.Linear(4, 1)\n",
    "        self.groups = nn.ModuleList([g1, g2])\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for group in self.groups:\n",
    "            x = group(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.202181Z",
     "start_time": "2020-02-12T23:04:54.172278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SimpleModel(\n",
       "  (fc1): Linear(in_features=2, out_features=2, bias=True)\n",
       "  (fc2): Linear(in_features=2, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snet = SimpleModel(DIM)\n",
    "snet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.348093Z",
     "start_time": "2020-02-12T23:04:54.319302Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 762,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lr_optimizer(snet, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.474158Z",
     "start_time": "2020-02-12T23:04:54.443159Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonmamin/ml_htools/ml_htools/torch_utils.py:203: UserWarning: More learning rates than layer groups. Last LRs will not be used.\n",
      "  data = [{'params': group.parameters(), 'lr': lr}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.003\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 763,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lr_optimizer(snet, [3e-3, 1e-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.610609Z",
     "start_time": "2020-02-12T23:04:54.579279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [((2, 2), False), ((2,), False), ((1, 2), False), ((1,), False)]\n",
      "1 [((2, 2), False), ((2,), False), ((1, 2), False), ((1,), True)]\n",
      "2 [((2, 2), False), ((2,), False), ((1, 2), True), ((1,), True)]\n",
      "3 [((2, 2), False), ((2,), True), ((1, 2), True), ((1,), True)]\n",
      "4 [((2, 2), True), ((2,), True), ((1, 2), True), ((1,), True)]\n"
     ]
    }
   ],
   "source": [
    "snet.freeze()\n",
    "for n in range(5):\n",
    "    snet.unfreeze(n_layers=n)\n",
    "    print(n, snet.trainable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.730875Z",
     "start_time": "2020-02-12T23:04:54.700956Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As expected, got AttributeError('SimpleModel' object has no attribute 'groups').\n"
     ]
    }
   ],
   "source": [
    "snet.freeze()\n",
    "with assert_raises(AttributeError) as ar:\n",
    "    for n in range(3):\n",
    "        snet.unfreeze(n_groups=n)\n",
    "        print(n, snet.trainable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.876037Z",
     "start_time": "2020-02-12T23:04:54.845628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GroupedModel(\n",
       "  (groups): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=8, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 766,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnet = GroupedModel(DIM)\n",
    "gnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:54.960797Z",
     "start_time": "2020-02-12T23:04:54.932008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.003\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 767,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lr_optimizer(gnet, [1e-3, 3e-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.146069Z",
     "start_time": "2020-02-12T23:04:55.115453Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonmamin/ml_htools/ml_htools/torch_utils.py:199: UserWarning: Fewer learning rates than layer groups. Repeating last LR.\n",
      "  warnings.warn('Fewer learning rates than layer groups. '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 0.001\n",
       "    lr: 0.001\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_lr_optimizer(gnet, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.210871Z",
     "start_time": "2020-02-12T23:04:55.181666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), False), ((1, 4), False), ((1,), False)]\n",
      "1 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), False), ((1, 4), True), ((1,), True)]\n",
      "2 [((8, 2), True), ((8,), True), ((4, 8), True), ((4,), True), ((1, 4), True), ((1,), True)]\n"
     ]
    }
   ],
   "source": [
    "gnet.freeze()\n",
    "for n in range(3):\n",
    "    gnet.unfreeze(n_groups=n)\n",
    "    print(n, gnet.trainable())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.351933Z",
     "start_time": "2020-02-12T23:04:55.320796Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), False), ((1, 4), False), ((1,), False)]\n",
      "1 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), False), ((1, 4), False), ((1,), True)]\n",
      "2 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), False), ((1, 4), True), ((1,), True)]\n",
      "3 [((8, 2), False), ((8,), False), ((4, 8), False), ((4,), True), ((1, 4), True), ((1,), True)]\n",
      "4 [((8, 2), False), ((8,), False), ((4, 8), True), ((4,), True), ((1, 4), True), ((1,), True)]\n",
      "5 [((8, 2), False), ((8,), True), ((4, 8), True), ((4,), True), ((1, 4), True), ((1,), True)]\n",
      "6 [((8, 2), True), ((8,), True), ((4, 8), True), ((4,), True), ((1, 4), True), ((1,), True)]\n"
     ]
    }
   ],
   "source": [
    "gnet.freeze()\n",
    "for n in range(7):\n",
    "    gnet.unfreeze(n_layers=n)\n",
    "    print(n, gnet.trainable())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.605526Z",
     "start_time": "2020-02-12T23:04:55.575963Z"
    }
   },
   "outputs": [],
   "source": [
    "@auto_repr\n",
    "class TorchCallback:\n",
    "    \n",
    "    def on_train_begin(self, trainer, lrs):\n",
    "        pass\n",
    "    \n",
    "    def on_train_end(self, trainer, epoch, stats, val_stats):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_begin(self, trainer, epoch, stats, val_stats):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        pass\n",
    "    \n",
    "    def on_batch_begin(self, trainer, i, sum_i, stats):\n",
    "        pass\n",
    "    \n",
    "    def on_batch_end(self, trainer, i, sum_i, stats):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.745261Z",
     "start_time": "2020-02-12T23:04:55.714171Z"
    }
   },
   "outputs": [],
   "source": [
    "class BasicConfig(TorchCallback):\n",
    "    \"\"\"Handles basic model tasks like putting the model on the GPU\n",
    "    and switching between train and eval modes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, priority=0):\n",
    "        self.priority = priority\n",
    "    \n",
    "    def on_train_begin(self, trainer, lrs):\n",
    "        if not isinstance(lrs, Iterable): lrs = [lrs]\n",
    "        trainer.net.to(DEVICE)\n",
    "        update_optimizer(trainer.optim, *lrs)\n",
    "\n",
    "    def on_epoch_begin(self, trainer, *args, **kwargs):\n",
    "        trainer.net.train()\n",
    "        \n",
    "    def on_train_end(self, trainer, *args, **kwargs):\n",
    "        trainer.logger.info('Training complete. Model in eval mode.')\n",
    "        trainer.net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:55.888089Z",
     "start_time": "2020-02-12T23:04:55.857299Z"
    }
   },
   "outputs": [],
   "source": [
    "class StatsHandler(TorchCallback):\n",
    "    \"\"\"This updates metrics at the end of each epoch to account for\n",
    "    potentially varying batch sizes.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, priority=5):\n",
    "        self.priority = priority\n",
    "        \n",
    "    def on_epoch_begin(self, trainer, epoch, stats, val_stats):\n",
    "        \"\"\"Resets stats at the start of each epoch.\"\"\"\n",
    "        stats.clear()\n",
    "        \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        \"\"\"Computes (possibly weighted) averages of mini-batch stats\n",
    "        at the end of each epoch.\n",
    "        \"\"\"\n",
    "        for group in (stats, val_stats):\n",
    "            for k, v in group.items():\n",
    "                if k == 'batch_size': continue\n",
    "                group[k] = np.average(v, weights=group['batch_size'])\n",
    "            group.pop('batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:04:56.267056Z",
     "start_time": "2020-02-12T23:04:56.234675Z"
    }
   },
   "outputs": [],
   "source": [
    "class MetricPrinter(TorchCallback):\n",
    "    \"\"\"Prints metrics at the end of each epoch. This is one of the \n",
    "    default callbacks provided in BaseModel - it does not need to\n",
    "    be passed in explicitly.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, priority=10):\n",
    "        self.priority = priority\n",
    "        \n",
    "    def on_train_begin(self, trainer, *args, **kwargs):\n",
    "        trainer.logger = trainer.get_logger(\n",
    "            os.path.join(trainer.out_dir, 'train.log'),\n",
    "            fmt='\\n%(asctime)s\\n %(message)s'\n",
    "        )\n",
    "    \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        data = [[k, v, val_stats[k]] for k, v in stats.items()]\n",
    "        table = tabulate(data, headers=['Metric', 'Train', 'Validation'], \n",
    "                         tablefmt='github', floatfmt='.4f')\n",
    "        trainer.logger.info(f'Epoch {epoch}\\n\\n{table}\\n\\n{\"=\"*9}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:56:45.647037Z",
     "start_time": "2020-02-12T23:56:45.611908Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopper(TorchCallback):\n",
    "    \n",
    "    def __init__(self, goal, metric='loss', min_improvement=0.0, patience=3, \n",
    "                 priority=15):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        goal: str\n",
    "            Indicates what we want to do to the metric in question.\n",
    "            Either 'min' or 'max'. E.g. metric 'loss' should have goal 'min'\n",
    "            while metric 'precision' should have goal 'max'.\n",
    "        metric: str\n",
    "            Quantity to monitor. This will always be computed on the \n",
    "            validation set.\n",
    "        min_improvement: float\n",
    "            Amount of change needed to qualify as improvement. For example,\n",
    "            min_improvement of 0.0 means any improvement is sufficient. With\n",
    "            a min_improvent of 0.2, we will stop training even if the\n",
    "            quantity improves by, for example, 0.1.\n",
    "        patience: int\n",
    "            Number of acceptable epochs without improvement. E.g. patience=0 \n",
    "            means the metric must improve every epoch for training to continue.            \n",
    "        \"\"\"\n",
    "        # Will use op like: self.op(new_val, current_best)\n",
    "        if goal == 'min':\n",
    "            self.init_metric = self.best_metric = float('inf')\n",
    "            self.op = lt\n",
    "            self.op_best = sub\n",
    "        elif goal == 'max':\n",
    "            self.init_metric = self.best_metric = float('-inf')\n",
    "            self.op = gt\n",
    "            self.op_best = add\n",
    "        else:\n",
    "            raise ValueError('Goal must be \"min\" or \"max\".')\n",
    "           \n",
    "        self.priority = priority\n",
    "        self.metric = metric\n",
    "        self.min_improvement = min_improvement\n",
    "        self.patience = patience\n",
    "        self.since_improvement = 0\n",
    "        \n",
    "    def on_train_begin(self, trainer, *args, **kwargs):\n",
    "        \"\"\"Resets tracked variables at start of training.\"\"\"\n",
    "        self.best_metric = self.init_metric\n",
    "        self.since_improvement = 0\n",
    "    \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        # Error handling.\n",
    "        new_val = val_stats.get(self.metric)\n",
    "        if new_val is None:\n",
    "            trainer.logger.info(f'EarlyStopper could not find {self.metric}.'\n",
    "                                f'Callback behavior may not be enforced.')\n",
    "        \n",
    "        # Expected behavior.\n",
    "        if self.op(new_val, self.op_best(self.best_metric, self.min_improvement)):\n",
    "            self.best_metric = new_val\n",
    "            self.since_improvement = 0\n",
    "        else:\n",
    "            self.since_improvement += 1\n",
    "            if self.since_improvement > self.patience:\n",
    "                trainer.logger.info(\n",
    "                    f'EarlyStopper halting training: validation {self.metric} '\n",
    "                    f'has not improved enough in {self.since_improvement} epochs.'\n",
    "                )\n",
    "                trainer._stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:01:31.432073Z",
     "start_time": "2020-02-13T00:01:31.399158Z"
    }
   },
   "outputs": [],
   "source": [
    "class PerformanceThreshold(TorchCallback):\n",
    "    \n",
    "    def __init__(self, metric, goal, threshold, skip_epochs=0, split='val',\n",
    "                 priority=15):\n",
    "        assert split in ('train', 'val'), 'Split must be \"train\" or \"val\".'\n",
    "        assert goal in ('min', 'max'), 'Goal must be \"min\" or \"max\"'\n",
    "        \n",
    "        self.priority = priority\n",
    "        self.metric = metric\n",
    "        self.threshold = threshold\n",
    "        self.skip_epochs = skip_epochs\n",
    "        self.split = split\n",
    "        self.op = gt if goal == 'min' else lt\n",
    "        \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        if epoch <= self.skip_epochs:\n",
    "            return\n",
    "        \n",
    "        # Error handling.\n",
    "        data = val_stats if self.split == 'val' else stats\n",
    "        new_val = data.get(self.metric)\n",
    "        if new_val is None:\n",
    "            trainer.logger.info(f'{self.metric} not found in metrics.'\n",
    "                                 'PerformanceThreshold may not be enforced.')\n",
    "            return\n",
    "        \n",
    "        # Expected behavior.\n",
    "        if self.op(new_val, self.threshold):\n",
    "            trainer.logger.info(\n",
    "                f'PerformanceThreshold halting training: {self.metric} '\n",
    "                f'of {new_val:.4f} did not meet threshold.'\n",
    "            )\n",
    "            trainer._stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:31.109829Z",
     "start_time": "2020-02-13T00:14:31.075174Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelCheckpoint(TorchCallback):\n",
    "    \n",
    "    def __init__(self, metric='loss', goal='min', priority=25):\n",
    "        # Will use op like: self.op(new_val, current_best)\n",
    "        if goal == 'min':\n",
    "            self.init_metric = self.best_metric = float('inf')\n",
    "            self.op = lt\n",
    "            self.op_best = sub\n",
    "        elif goal == 'max':\n",
    "            self.init_metric = self.best_metric = float('-inf')\n",
    "            self.op = gt\n",
    "            self.op_best = add\n",
    "        else:\n",
    "            raise ValueError('Goal must be \"min\" or \"max\".')\n",
    "\n",
    "        self.priority = priority\n",
    "        self.metric = metric\n",
    "        self.model_dir = None\n",
    "        \n",
    "    def on_train_begin(self, trainer, *args, **kwargs):\n",
    "        self.best_metric = self.init_metric\n",
    "        \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        new_val = val_stats.get(self.metric)\n",
    "        # Error handling.\n",
    "        if new_val is None:\n",
    "            trainer.logger.info(f'{self.metric} not found in metrics.'\n",
    "                                 'ModelCheckpoint may not save models.')\n",
    "            \n",
    "        # Expected behavior.\n",
    "        if self.op(new_val, self.best_metric):\n",
    "            trainer.logger.info(\n",
    "                f'Saving model. {self.metric} improved from '\n",
    "                f'{self.best_metric} to {new_val}.'\n",
    "            )\n",
    "            trainer.save(f'model.pkl')\n",
    "            self.best_metric = new_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:32.083852Z",
     "start_time": "2020-02-13T00:14:32.054749Z"
    }
   },
   "outputs": [],
   "source": [
    "class CSVLogger(TorchCallback):\n",
    "    \"\"\"Separate from StatsHandler in case we don't want to log outputs.\"\"\"\n",
    "    \n",
    "    def __init__(self, mode='epoch', file_fmt='{}_stats.csv', priority=90):\n",
    "        assert mode in ('epoch', 'batch'), \\\n",
    "            'Mode must be \"epoch\" or \"batch\".'\n",
    "        \n",
    "        self.priority = priority\n",
    "        self.mode = mode\n",
    "        self.history = defaultdict(list)\n",
    "        self.fname = file_fmt.format(mode)\n",
    "        \n",
    "    def on_train_begin(self, trainer, lrs):\n",
    "        pass\n",
    "        \n",
    "    def on_batch_end(self, trainer, i, sum_i, stats):\n",
    "        if self.mode != 'batch':\n",
    "            return\n",
    "        \n",
    "        pass\n",
    "        \n",
    "    def on_epoch_end(self, trainer, epoch, stats, val_stats):\n",
    "        if self.mode != 'epoch':\n",
    "            return\n",
    "        \n",
    "    def write_csv(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:32.301509Z",
     "start_time": "2020-02-13T00:14:32.270607Z"
    }
   },
   "outputs": [],
   "source": [
    "class S3Uploader(TorchCallback):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, prefix, priority=95):\n",
    "        self.prefix = prefix\n",
    "        self.priority = priority\n",
    "    \n",
    "    def on_train_end(self, trainer, *args, **kwargs):\n",
    "        paths = [f.path for f in os.scandir(trainer.out_dir)\n",
    "                 if f.is_file() and not f.name.startswith('.')]\n",
    "        s3 = S3tool()\n",
    "        try:\n",
    "            s3.upload_files(paths, trainer.bucket, self.prefix)\n",
    "        except Exception as e:\n",
    "            trainer.logger.error(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:32.521992Z",
     "start_time": "2020-02-13T00:14:32.493516Z"
    }
   },
   "outputs": [],
   "source": [
    "class EC2Closer(TorchCallback):\n",
    "    \n",
    "    def __init__(self, priority=100):\n",
    "        self.priority = priority\n",
    "        \n",
    "    def on_train_end(self, trainer, *args, **kwargs):\n",
    "        stop_instance()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:32.759540Z",
     "start_time": "2020-02-13T00:14:32.730480Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelUnfreezer(TorchCallback):\n",
    "    \"\"\"Gradually unfreeze a model during training.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, idx, mode='epoch', priority=25):\n",
    "        self.priority = priority\n",
    "        \n",
    "    def on_batch_begin(self):\n",
    "        pass\n",
    "    \n",
    "    def on_epoch_begin(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:32.970841Z",
     "start_time": "2020-02-13T00:14:32.942338Z"
    }
   },
   "outputs": [],
   "source": [
    "def back_translate(text, to, from_lang='en'):\n",
    "    return TextBlob(text)\\\n",
    "        .translate(to=to)\\\n",
    "        .translate(from_lang=to, to=from_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:33.116161Z",
     "start_time": "2020-02-13T00:14:33.088575Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "Visit ESPN to get up-to-the-minute sports news coverage, scores, highlights and commentary for NFL, MLB, NBA, College Football, NCAA Basketball and more.\n",
    "\"\"\"\n",
    "# back_translate(text, 'es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n",
    "Keep sklearn pattern with y_true as first argument.\n",
    "\n",
    "For classification problems, round probabilities once instead of in every metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:33.682249Z",
     "start_time": "2020-02-13T00:14:33.654359Z"
    }
   },
   "outputs": [],
   "source": [
    "def hasarg(func, arg):\n",
    "    \"\"\"Checks if a function has a given argument. \n",
    "    Works with *args and **kwargs as well.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    func: function\n",
    "    arg: str\n",
    "        Name of argument to look for.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "    \"\"\"\n",
    "    return arg in inspect.signature(func).parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:33.842708Z",
     "start_time": "2020-02-13T00:14:33.814251Z"
    }
   },
   "outputs": [],
   "source": [
    "def percent_positive(y_true, y_pred):\n",
    "    \"\"\"Compute the percent of predictions that are positive. This\n",
    "    can help us identify when a model is predicting all ones or zeros.\n",
    "    \"\"\"\n",
    "    return (y_pred == 1).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:34.020316Z",
     "start_time": "2020-02-13T00:14:33.992114Z"
    }
   },
   "outputs": [],
   "source": [
    "def mean_soft_prediction(y_true, y_score):\n",
    "    \"\"\"Compute the mean predicted probability.\"\"\"\n",
    "    return y_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:34.182087Z",
     "start_time": "2020-02-13T00:14:34.153117Z"
    }
   },
   "outputs": [],
   "source": [
    "def batch_size(y_true, y_pred):\n",
    "    \"\"\"Count the number of items in the current batch.\"\"\"\n",
    "    return y_true.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 892,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:34.335565Z",
     "start_time": "2020-02-13T00:14:34.306113Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False]"
      ]
     },
     "execution_count": 892,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hasarg(roc_auc_score, val) for val in ('y_score', 'y_pred')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:34.483647Z",
     "start_time": "2020-02-13T00:14:34.453114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True]"
      ]
     },
     "execution_count": 893,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[hasarg(precision_score, val) for val in ('y_score', 'y_pred')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:35.089431Z",
     "start_time": "2020-02-13T00:14:35.060615Z"
    }
   },
   "outputs": [],
   "source": [
    "DIM = 2\n",
    "metrics = [accuracy_score, \n",
    "           precision_score, \n",
    "           recall_score, \n",
    "           percent_positive,\n",
    "           mean_soft_prediction\n",
    "          ]\n",
    "callbacks = [EarlyStopper('max', 'accuracy', patience=3),\n",
    "             PerformanceThreshold('recall', 'max', 0.25, skip_epochs=5),\n",
    "             CSVLogger(),\n",
    "             ModelCheckpoint(),\n",
    "             S3Uploader('mytorch_test')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:14:35.339966Z",
     "start_time": "2020-02-13T00:14:35.309947Z"
    }
   },
   "outputs": [],
   "source": [
    "train = Data(n=34, dim=DIM)\n",
    "val = Data(n=30, dim=DIM)\n",
    "\n",
    "dl_train = DataLoader(train, batch_size=8, shuffle=True)\n",
    "dl_val = DataLoader(val, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:15:08.803820Z",
     "start_time": "2020-02-13T00:15:08.772697Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Trainer(criterion='binary_cross_entropy_with_logits', out_dir='../data/v1', bucket='datascience-delphi-dev')\n",
       "\n",
       "Datasets: 34 train rows, 30 val rows\n",
       "\n",
       "Optimizer: RMSprop (\n",
       "Parameter Group 0\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    eps: 0.001\n",
       "    lr: 0.003\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       "\n",
       "Parameter Group 1\n",
       "    alpha: 0.99\n",
       "    centered: False\n",
       "    eps: 0.001\n",
       "    lr: 0.003\n",
       "    momentum: 0\n",
       "    weight_decay: 0\n",
       ")\n",
       "\n",
       "GroupedModel(\n",
       "  (groups): ModuleList(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=8, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
       "      (3): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
       "  )\n",
       "))"
      ]
     },
     "execution_count": 898,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = Trainer(gnet, train, val, dl_train, dl_val, F.binary_cross_entropy_with_logits, \n",
    "            '../data/v1', 'datascience-delphi-dev', torch.optim.RMSprop, \n",
    "            last_act=torch.sigmoid, metrics=metrics, callbacks=callbacks)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 899,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-13T00:15:10.584706Z",
     "start_time": "2020-02-13T00:15:09.340007Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-02-12 16:15:09,397\n",
      " Epoch 1\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.1176 |       0.0014 |\n",
      "| accuracy             |  0.9412 |       1.0000 |\n",
      "| precision            |  0.9706 |       1.0000 |\n",
      "| recall               |  0.9664 |       1.0000 |\n",
      "| percent_positive     |  0.6471 |       0.6333 |\n",
      "| mean_soft_prediction |  0.6581 |       0.6331 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-12 16:15:09,398\n",
      " Saving model. loss improved from inf to 0.0014312235619096706.\n",
      "Data written to ../data/v1/model.pkl.\n",
      "\n",
      "2020-02-12 16:15:09,430\n",
      " Epoch 2\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.0222 |       0.0037 |\n",
      "| accuracy             |  1.0000 |       1.0000 |\n",
      "| precision            |  1.0000 |       1.0000 |\n",
      "| recall               |  1.0000 |       1.0000 |\n",
      "| percent_positive     |  0.6471 |       0.6333 |\n",
      "| mean_soft_prediction |  0.6288 |       0.6365 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-12 16:15:09,461\n",
      " Epoch 3\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.0030 |       0.0051 |\n",
      "| accuracy             |  1.0000 |       1.0000 |\n",
      "| precision            |  1.0000 |       1.0000 |\n",
      "| recall               |  1.0000 |       1.0000 |\n",
      "| percent_positive     |  0.6471 |       0.6333 |\n",
      "| mean_soft_prediction |  0.6445 |       0.6378 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-12 16:15:09,490\n",
      " Epoch 4\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.0022 |       0.0062 |\n",
      "| accuracy             |  1.0000 |       1.0000 |\n",
      "| precision            |  0.9412 |       1.0000 |\n",
      "| recall               |  0.9412 |       1.0000 |\n",
      "| percent_positive     |  0.6471 |       0.6333 |\n",
      "| mean_soft_prediction |  0.6454 |       0.6388 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-12 16:15:09,520\n",
      " Epoch 5\n",
      "\n",
      "| Metric               |   Train |   Validation |\n",
      "|----------------------|---------|--------------|\n",
      "| loss                 |  0.0017 |       0.0075 |\n",
      "| accuracy             |  1.0000 |       1.0000 |\n",
      "| precision            |  1.0000 |       1.0000 |\n",
      "| recall               |  1.0000 |       1.0000 |\n",
      "| percent_positive     |  0.6471 |       0.6333 |\n",
      "| mean_soft_prediction |  0.6458 |       0.6399 |\n",
      "\n",
      "=========\n",
      "\n",
      "2020-02-12 16:15:09,521\n",
      " EarlyStopper halting training: validation accuracy has not improved enough in 4 epochs.\n",
      "\n",
      "2020-02-12 16:15:09,521\n",
      " Training complete. Model in eval mode.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/harrisonmamin/ml_htools/ml_htools/torch_utils.py:231: UserWarning: Fewer learning rates than layer groups. Repeating last LR.\n",
      "  warnings.warn('Fewer learning rates than layer groups. '\n",
      "/Users/harrisonmamin/.pyenv/versions/3.7.4/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/harrisonmamin/.pyenv/versions/3.7.4/envs/main/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../data/v1/train.log\n",
      "Bucket: datascience-delphi-dev\n",
      "Key: mytorch_test/train.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: ../data/v1/model.pkl\n",
      "Bucket: datascience-delphi-dev\n",
      "Key: mytorch_test/model.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "t.fit(10, [3e-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 802,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:07:02.736502Z",
     "start_time": "2020-02-12T23:07:02.701189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data written to ../data/v1/trainer.zip.\n"
     ]
    }
   ],
   "source": [
    "t.save('trainer.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 803,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-02-12T23:07:04.270750Z",
     "start_time": "2020-02-12T23:07:04.127054Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object loaded from ../data/v1/trainer.zip.\n",
      "Trainer(criterion='binary_cross_entropy_with_logits', out_dir='../data/v1', bucket='datascience-delphi-dev')\n",
      "\n",
      "Datasets: 34 train rows, 30 val rows\n",
      "\n",
      "Optimizer: RMSprop (\n",
      "Parameter Group 0\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 0.001\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      "\n",
      "Parameter Group 1\n",
      "    alpha: 0.99\n",
      "    centered: False\n",
      "    eps: 0.001\n",
      "    lr: 0.03\n",
      "    momentum: 0\n",
      "    weight_decay: 0\n",
      ")\n",
      "\n",
      "GroupedModel(\n",
      "  (groups): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Linear(in_features=2, out_features=8, bias=True)\n",
      "      (1): LeakyReLU(negative_slope=0.01)\n",
      "      (2): Linear(in_features=8, out_features=4, bias=True)\n",
      "      (3): LeakyReLU(negative_slope=0.01)\n",
      "    )\n",
      "    (1): Linear(in_features=4, out_features=1, bias=True)\n",
      "  )\n",
      "))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 803,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = Trainer.from_file(os.path.join('..', 'data', 'v1', 'trainer.zip'))\n",
    "print(t2)\n",
    "del t2; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
